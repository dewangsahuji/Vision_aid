üß© 1. App Overview

Type: Cross-platform AI app (Android + iOS)
Interface: Voice-only (optional simple UI)
Core: Python backend (Flask/FastAPI) + Mobile front-end (Kivy/Flutter)
Mode: Works fully offline
Purpose: Computer vision + speech + AI reasoning on-device

-----------------------------------------------------------------------------------------

‚öôÔ∏è 3. Technology Stack

| **Layer**              | **Tool / Library**                               |
| ---------------------- | ------------------------------------------------ |
| **Frontend**           | Kivy (Python UI) / Flutter *(optional)*          |
| **Backend**            | FastAPI / Flask                                  |
| **Speech Recognition** | Whisper.cpp *(offline)* / Vosk                   |
| **Text-to-Speech**     | Edge-TTS / Coqui-AI / pyttsx3                    |
| **Computer Vision**    | OpenCV / YOLOv8n / EasyOCR / BLIP                |
| **AI Reasoning**       | LangChain / Phi-3-mini / Llama3 / Ollama         |
| **Database**           | SQLite + FAISS                                   |
| **Sensors**            | Android API *(via Pyjnius / Flutter plugins)*    |
| **Packaging**          | Buildozer *(Kivy ‚Üí Android APK)* / Flutter build |


-----------------------------------------------------------------------------------------

üß† 5. Core Features (Technical Implementation)
Feature	Implementation
üéôÔ∏è Voice Commands	Whisper.cpp for STT ‚Üí LangChain parser ‚Üí executes module
üîä Voice Output	Edge-TTS ‚Üí AudioQueue playback
üëÅÔ∏è Object Detection	YOLOv8n ‚Üí bounding boxes ‚Üí spoken output
üìñ Text Reader	EasyOCR ‚Üí extracted text ‚Üí summarized via LLM ‚Üí TTS
üíµ Currency Detector	MobileNetV3 ‚Üí predicts denomination
üòÄ Face Recognition	FaceNet + embedding database
üß≠ Navigation Guidance	Camera + GPS (if outdoors) ‚Üí simple directional speech
‚öôÔ∏è Agentic Decisions	DecisionAgent routes tasks intelligently
üß© Context Awareness	Logs user actions + last environment
üß¨ Offline Mode	All inference done locally (TFLite / ONNX)

-----------------------------------------------------------------------------------------

‚ö° 8. Phase-Wise Development Plan (8 Weeks)
Week	Task	Deliverable
1	Setup Kivy UI + TTS	App speaks messages
2	Integrate Whisper STT	Speech ‚Üí Text commands
3	Add Object Detection	Camera ‚Üí Object ‚Üí Voice output
4	Add OCR + Currency	Text reading + note recognition
5	Add LLM + LangChain	Intent routing (agentic brain)
6	Add Face + Navigation	FaceNet + GPS integration
7	Add Context Memory	SQLite + FAISS memory system
8	Optimize + Build APK	Fully offline, production-ready APK

-----------------------------------------------------------------------------------------
üß∞ 9. Model Suggestions (Lightweight for Mobile)

| Task             | Model                  | Format           |
| ---------------- | ---------------------- | ---------------- |
| STT              | Whisper Tiny / Vosk    | `.bin` / `.onnx` |
| Object Detection | YOLOv8n                | `.tflite`        |
| OCR              | EasyOCR (light)        | Python model     |
| Scene Captioning | BLIP base              | ONNX             |
| Face Recognition | MobileFaceNet          | `.tflite`        |
| Emotion          | FER Tiny               | `.tflite`        |
| Reasoning        | Phi-3 Mini / Llama3 1B | Ollama local     |
| TTS              | Edge-TTS / Coqui       | Local or API     |

---------------------------------------------------------------------------------------

üîí 10. Privacy & Offline Capabilities

‚úÖ No data leaves device
‚úÖ All inference offline (TFLite / ONNX)
‚úÖ Encrypted local memory (SQLite + AES)
‚úÖ Optional cloud sync via user permission

---------------------------------------------------------------------------------------

‚úÖ 12. Final Output

App Name: VisioAid
Platform: Android (primary), iOS (future)
Core: AI + CV + Speech + Agents
Operation: 100% Voice-based
USP: Offline, private, and accessible






